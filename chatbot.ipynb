{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5pQCinoEGdv"
   },
   "outputs": [],
   "source": [
    "pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndt32OXxJL6c"
   },
   "outputs": [],
   "source": [
    "pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bjh1GHRbEJu2"
   },
   "outputs": [],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQ9IAHtnEL9U"
   },
   "outputs": [],
   "source": [
    "pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9943,
     "status": "ok",
     "timestamp": 1734250906488,
     "user": {
      "displayName": "rowaiba zaman",
      "userId": "00111539776649296297"
     },
     "user_tz": -300
    },
    "id": "pjQG87CTEZ22",
    "outputId": "a1c4af89-c9aa-41a4-fcee-12aea5b77461"
   },
   "outputs": [],
   "source": [
    "# pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "id": "6_0hdmSiIyEz"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "import pdfplumber\n",
    "\n",
    "#load documents\n",
    "def load_documents(data_dir):\n",
    "    \"\"\"Load text data from PDFs and TXT files.\"\"\"\n",
    "    documents = []\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            with pdfplumber.open(file_path) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    documents.append(page.extract_text())\n",
    "        elif file_name.endswith(\".txt\"):\n",
    "            loader = TextLoader(file_path)\n",
    "            docs = loader.load()\n",
    "            documents.extend([doc.page_content for doc in docs])\n",
    "    return documents\n",
    "\n",
    "\n",
    "#process docs with hugging face\n",
    "def process_documents(docs):\n",
    "    \"\"\"Split documents into chunks and generate embeddings.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return chunks, embeddings\n",
    "\n",
    "#store the vector\n",
    "def build_vector_store(chunks, embeddings):\n",
    "    \"\"\"Create and save a FAISS vector store.\"\"\"\n",
    "    vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "    vector_store.save_local(\"retriever_index\")\n",
    "    return vector_store\n",
    "\n",
    "#load model\n",
    "def load_llm():\n",
    "    \"\"\"Load the LLM. text generation\"\"\"\n",
    "    pipe = pipeline(\"text-generation\", model=\"gpt2\", max_new_tokens=50)\n",
    "    return HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# Building the QA Chain\n",
    "def build_chain(llm, vector_store):\n",
    "    # Convert the FAISS vector store into a retriever\n",
    "    retriever = vector_store.as_retriever()\n",
    "\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "    return qa_chain\n",
    "\n",
    "# Load pre-built index or create a new one\n",
    "def get_chain():\n",
    "    if not os.path.exists(\"retriever_index\"):\n",
    "        print(\"Building the index from documents...\")\n",
    "        docs = load_documents(data_dir=\"path_to_dataset\")  # Change path to your dataset directory\n",
    "        chunks, embeddings = process_documents(docs)\n",
    "        vector_store = build_vector_store(chunks, embeddings)\n",
    "        llm = load_llm()\n",
    "        chain = build_chain(llm, vector_store)\n",
    "    else:\n",
    "        print(\"Loading the pre-built index...\")\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        vector_store = FAISS.load_local(\"retriever_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "        llm = load_llm()\n",
    "        chain = build_chain(llm, vector_store)\n",
    "\n",
    "    return chain\n",
    "\n",
    "#response to query\n",
    "def respond_to_query(user_input):\n",
    "    chain = get_chain()\n",
    "    response = chain.invoke(user_input)\n",
    "    raw_response = response.get('result', '')\n",
    "    helpful_answer_start = raw_response.find(\"Helpful Answer:\")\n",
    "    if helpful_answer_start != -1:\n",
    "        helpful_answer = raw_response[helpful_answer_start + len(\"Helpful Answer:\"):].strip()\n",
    "    else:\n",
    "        helpful_answer = raw_response.strip()\n",
    "    cleaned_response = helpful_answer.replace('\\n', ' ').strip()\n",
    "\n",
    "    return f\"{cleaned_response}\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Launch the Gradio interface.\"\"\"\n",
    "    iface = gr.Interface(\n",
    "        fn=respond_to_query,\n",
    "        inputs=gr.Textbox(label=\"Ask me anything:\", placeholder=\"Type your question here...\"),\n",
    "        outputs=gr.Textbox(label=\"Bot's Response\"),\n",
    "        title=\"Mental Wellness AI Chatbot\",\n",
    "    )\n",
    "\n",
    "    iface.launch(debug=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMAa0GXd2GPspSZp1HZUFe8",
   "mount_file_id": "1LLpW6LvhHdq8Y7VlA72E4qEWqPwkICBE",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
